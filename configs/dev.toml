[system]
# Load language from environment variable(It is set by the hook)
language = "${env:DBGPT_LANG:-zh}"
log_level = "INFO"
api_keys = []
encrypt_key = "your_secret_key"

# Server Configurations
[service.web]
host = "127.0.0.1"
port = 5670

[service.web.database]
type = "sqlite"
path = "pilot/meta_data/dbgpt.db"
#[service.web.database]
# type = "mysql"
# host = "127.0.0.1"
# port = 3306
# user = "root"
# database = "dbgpt"
# password = "aa12345678"

[service.model.worker]
host = "127.0.0.1"

[rag]
chunk_size=1000
chunk_overlap=0
similarity_top_k=5
similarity_score_threshold=0.0
max_chunks_once_load=10
max_threads=1
rerank_top_k=3
graph_community_summary_enabled="True"
enable_summary=true


[rag.storage]
[rag.storage.vector]
type = "Chroma"
persist_path = "pilot/data"

#type = "ElasticSearch"
#uri = "127.0.0.1"
#port = "19530"
#username="dbgpt"
#password=19530
[rag.storage.graph]
type = "TuGraph"
host="127.0.0.1"
port=7687
username="admin"
password="73@TuGraph"
enable_summary=true
enable_similarity_search=false

[rag.storage.full_text]
type = "ElasticSearch"
host="127.0.0.1"
port=9200




#GRAPH_COMMUNITY_SUMMARY_ENABLED=True  # enable the graph community summary
#TRIPLET_GRAPH_ENABLED=True  # enable the graph search for the triplets
#DOCUMENT_GRAPH_ENABLED=True  # enable the graph search for documents and chunks
#KNOWLEDGE_GRAPH_EXTRACTION_BATCH_SIZE=20  # the batch size of triplet extraction from the text
#COMMUNITY_SUMMARY_BATCH_SIZE=20  # the batch size of parallel community summary process




# Model Configurations
[models]
[[models.llms]]
#name = "deepseek-chat"
#provider = "proxy/deepseek"
#provider = "proxy/vol-deepseek"
#api_key = "${env:DEEPSEEK_API_KEY}"
#name = "${env:LLM_MODEL_NAME:-deepseek-chat}"
#provider = "${env:LLM_MODEL_PROVIDER:-proxy/deepseek}"
#api_url = "https://zdfmng.alipay.com/chat/completions"
#api_key = "sk-adf80a1b814cf1193422fabcd34ccc0a"
#api_key = "sk-04bec639baf54da7b743016e8536a459"

name = "Qwen2.5-72B-Instruct"
provider = "proxy/gitee"
api_key = "W7LRHBLWM0XMW0AGLDRKEITZNZCSUUHAVFOYWO1C"

[[models.embeddings]]
name = "bge-large-zh-v1.5"
provider = "proxy/openai"
api_url = "https://ai.gitee.com/v1/embeddings"
api_key = "W7LRHBLWM0XMW0AGLDRKEITZNZCSUUHAVFOYWO1C"